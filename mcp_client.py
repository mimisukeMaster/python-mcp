import asyncio
import os
from pathlib import Path
from mcp.client.stdio import stdio_client
from mcp import ClientSession, StdioServerParameters
from dotenv import load_dotenv

import google.generativeai as genai
from google.generativeai.types import FunctionDeclaration, Tool
from google.generativeai.protos import Part

load_dotenv()
try:
    api_key = os.environ["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
except KeyError:
    print("ã‚¨ãƒ©ãƒ¼: .envãƒ•ã‚¡ã‚¤ãƒ«ã« GOOGLE_API_KEY ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    exit()

def clean_schema_for_gemini(schema_dict):
    """'title'ã¨'default'ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’å†å¸°çš„ã«å‰Šé™¤ã™ã‚‹"""
    if isinstance(schema_dict, dict):
        schema_dict.pop('title', None)
        schema_dict.pop('default', None)
        for value in schema_dict.values():
            clean_schema_for_gemini(value)
    elif isinstance(schema_dict, list):
        for item in schema_dict:
            clean_schema_for_gemini(item)
    return schema_dict

async def main():
    try:
        python_executable = os.environ["PYTHON_EXE"]
        server_script_path_str = os.environ["SERVER_SCRIPT"]
    except KeyError as e:
        print(f"ã‚¨ãƒ©ãƒ¼: .envãƒ•ã‚¡ã‚¤ãƒ«ã« {e} ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        exit()
    
    python_path = Path(python_executable)
    script_path = Path(server_script_path_str)

    if not python_path.exists():
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: æŒ‡å®šã•ã‚ŒãŸPythonå®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return
    if not script_path.exists():
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: æŒ‡å®šã•ã‚ŒãŸã‚µãƒ¼ãƒãƒ¼ãƒ»ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return
    
    server_params = StdioServerParameters(
        command=python_executable,
        args=[f"{script_path}"]
    )
    
    async with stdio_client(server_params) as (read_stream, write_stream):
        async with ClientSession(read_stream, write_stream) as session:
            await session.initialize()
            print("âœ… MCPã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã—ã¾ã—ãŸã€‚")

            mcp_tools = await session.list_tools()
            gemini_tool_declarations = []
            for tool in mcp_tools.tools:
                params_schema = tool.inputSchema.copy()
                cleaned_schema = clean_schema_for_gemini(params_schema)
                gemini_tool_declarations.append(
                    FunctionDeclaration(
                        name=tool.name, description=tool.description, parameters=cleaned_schema
                    )
                )
            gemini_tools = [Tool(function_declarations=gemini_tool_declarations)]
            
            if gemini_tool_declarations:
                print(f"âœ… ã‚µãƒ¼ãƒãƒ¼ãƒ„ãƒ¼ãƒ« '{', '.join([t.name for t in gemini_tool_declarations])}' ã‚’èªè­˜ã—ã¾ã—ãŸã€‚")
            
            print("----------------------------------------------------")

            system_instruction = (
                "ã‚ãªãŸã¯çŸ­ã„è§£èª¬å‹•ç”»ã‚’ç”Ÿæˆã™ã‚‹å°‚é–€å®¶ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
                "ä»¥ä¸‹ã®æ‰‹é †ã«å³å¯†ã«å¾“ã£ã¦ãã ã•ã„:\n"
                "1. 'search_web'ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã„ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒˆãƒ”ãƒƒã‚¯ã«ã¤ã„ã¦èª¿æŸ»ã—ã¾ã™ã€‚\n"
                "2. æ¤œç´¢çµæœã«åŸºã¥ãã€100æ–‡å­—ç¨‹åº¦ã®ç°¡æ½”ãªãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åŸç¨¿ã‚’ä½œæˆã—ã¾ã™ã€‚\n"
                "3. 'synthesize_speech'ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã„ã€ãã®åŸç¨¿ã‚’éŸ³å£°ã«å¤‰æ›ã—ã¾ã™ã€‚\n"
                "4. åŸç¨¿ã®å†…å®¹ã«åˆã£ãŸã€é­…åŠ›çš„ã§å…·ä½“çš„ãªç”»åƒç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è€ƒæ¡ˆã—ã€'generate_image'ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã„ã¾ã™ã€‚\n"
                "5. 'create_video'ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã„ã€ç”Ÿæˆã•ã‚ŒãŸç”»åƒã¨éŸ³å£°ã®ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¦ã€æœ€çµ‚çš„ãªå‹•ç”»ã‚’çµ„ã¿ç«‹ã¦ã¾ã™ã€‚\n"
                "ã“ã‚Œã‚‰ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’é †ç•ªã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚ç¢ºèªã‚’æ±‚ã‚ãšã€ç›´æ¥è¨ˆç”»ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
                "--- \n"
                "é‡è¦ãƒ«ãƒ¼ãƒ«: \n"
                "- 'synthesize_speech'ãƒ„ãƒ¼ãƒ«ã¯WAVå½¢å¼(.wav)ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã™ã€‚\n"
                "- 'generate_image'ãƒ„ãƒ¼ãƒ«ã¯PNGå½¢å¼(.png)ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã™ã€‚\n"
                "- 'create_video'ãƒ„ãƒ¼ãƒ«ã¯MP4å½¢å¼(.mp4)ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã™ã€‚"
            )
            model = genai.GenerativeModel('gemini-2.5-pro', tools=gemini_tools, system_instruction=system_instruction)
            chat = model.start_chat(enable_automatic_function_calling=False)
            
            print("å‹•ç”»ã«ã—ãŸã„ãƒˆãƒ”ãƒƒã‚¯ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚(ä¾‹: é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã®ä»•çµ„ã¿ / exitã§çµ‚äº†)")
            while True:
                user_input = input("> ")
                if user_input.lower() == 'exit':
                    break

                print("ğŸ§  Geminiã«å‹•ç”»ä½œæˆãƒ—ãƒ©ãƒ³ã‚’å•ã„åˆã‚ã›ä¸­...")
                try:
                    response = await chat.send_message_async(user_input)
                    
                    while True:
                        if not response.candidates or not response.candidates[0].content.parts or not hasattr(response.candidates[0].content.parts[0], 'function_call') or not response.candidates[0].content.parts[0].function_call.name:
                            break
                        
                        api_requests_for_next_turn = []
                        for part in response.candidates[0].content.parts:
                            if part.function_call and part.function_call.name:
                                tool_name = part.function_call.name
                                tool_input = {key: value for key, value in part.function_call.args.items()}
                                
                                print(f"ğŸ¤– GeminiãŒãƒ„ãƒ¼ãƒ« '{tool_name}' ã®ä½¿ç”¨ã‚’æ±ºå®šã—ã¾ã—ãŸã€‚")
                                
                                result = await session.call_tool(tool_name, tool_input)
                                tool_result_text = result.content[0].text if result.content and hasattr(result.content[0], 'text') else str(result.content)
                                print(f"âœ… å®Ÿè¡Œçµæœ: {tool_result_text}")

                                api_requests_for_next_turn.append(
                                    Part(function_response={"name": tool_name, "response": {"result": tool_result_text}})
                                )
                        
                        print("ğŸ§  å®Ÿè¡Œçµæœã‚’Geminiã«å ±å‘Šã—ã€æ¬¡ã®æŒ‡ç¤ºã‚’å¾…ã£ã¦ã„ã¾ã™...")
                        response = await chat.send_message_async(api_requests_for_next_turn)
                    
                    final_response_text = chat.history[-1].parts[0].text
                    print(f"ğŸ‰ Gemini (ã‚¿ã‚¹ã‚¯å®Œäº†): {final_response_text}")

                except Exception as e:
                    print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

if __name__ == "__main__":
    asyncio.run(main())